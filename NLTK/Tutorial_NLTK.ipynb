{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial_NLTK.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viktor-chiarcos/Colab/blob/main/NLTK/Tutorial_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdKmzJW0sLdU"
      },
      "source": [
        "[![PALS0039 Logo](https://www.phon.ucl.ac.uk/courses/pals0039/images/pals0039logo.png)](https://www.phon.ucl.ac.uk/courses/pals0039/)\n",
        "\n",
        "# Tutorial Introduction to NLTK toolkit\n",
        "\n",
        "This notebook adapted from the [NLTK Book](http://www.nltk.org/book/ch01.html) Chapter 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lttCa3MSLvPU"
      },
      "source": [
        "(a) Import the NLTK module and download the text resources needed for the examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02RtRYj_p0Xb"
      },
      "source": [
        "import nltk\n",
        "\n",
        "# import all the resources for Natural Language Processing with Python\n",
        "nltk.download(\"book\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnfit4W3sTrc"
      },
      "source": [
        "(b) Take a sentence and tokenize into words. Then apply a part-of-speech tagger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOGPaeSbsdyk"
      },
      "source": [
        "sentence = \"\"\"At eight o'clock on Thursday morning\n",
        "Arthur didn't feel very good.\"\"\"\n",
        "\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "\n",
        "print(tokens)\n",
        "\n",
        "tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "print(tagged)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI60jDCnsr4L"
      },
      "source": [
        "(c) From the tagged words, identify the proper names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6qPgGT_swvT"
      },
      "source": [
        "entities = nltk.chunk.ne_chunk(tagged)\n",
        "\n",
        "print(entities)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DwjDdIps3XS"
      },
      "source": [
        "(d) get texts for corpus analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENYr8J42s8sD"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from nltk.book import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY_MZaJzMy0o"
      },
      "source": [
        "(e) generate a key-word in context concordance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9iOak9GverQ"
      },
      "source": [
        "text1.concordance(\"monstrous\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oytCl9s7NAY2"
      },
      "source": [
        "(f) find words with similar concordance to a given word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd3K23bdvmkX"
      },
      "source": [
        "print(text1)\n",
        "text1.similar(\"monstrous\")\n",
        "print(text2)\n",
        "text2.similar(\"monstrous\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgmP2biDNIqU"
      },
      "source": [
        "(g) find contexts which are similar for the given words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A-UOoySwF1A"
      },
      "source": [
        "text2.common_contexts([\"monstrous\", \"very\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u09dCNVNVwt"
      },
      "source": [
        "(h) plot where in the text certain words appear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV4BVaUDwbJ_"
      },
      "source": [
        "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhVpqEBtNaZv"
      },
      "source": [
        "(i) print the identity of a text, the length of the text and its vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amn1EmYDwrJ-"
      },
      "source": [
        "print(text3)\n",
        "print(len(text3))\n",
        "print(sorted(set(text3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS-0a_8kNiGY"
      },
      "source": [
        "(j) print some statistics of word occurrence in the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca_e5fjQxOCG"
      },
      "source": [
        "def lexical_diversity(text):\n",
        "  return len(set(text)) / len(text)\n",
        "def percentage(count, total):\n",
        "  return 100 * count / total\n",
        "\n",
        "print(lexical_diversity(text3))\n",
        "print(lexical_diversity(text5))\n",
        "print(percentage(text4.count('a'), len(text4)))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}